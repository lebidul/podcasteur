# ğŸ™ï¸ Podcasteur

**Ã‰diteur de podcasts automatisÃ© avec IA**

Podcasteur transforme vos enregistrements audio bruts en podcasts montÃ©s de qualitÃ©, avec deux modes de fonctionnement :
- **Automatique** : transcription + suggestions IA via Claude
- **Manuel** : dÃ©coupage prÃ©dÃ©fini dans un fichier JSON

---

## âœ¨ FonctionnalitÃ©s

- ğŸ”— **ConcatÃ©nation automatique** de plusieurs fichiers audio
- ğŸ¤ **Transcription** avec WhisperX (local, gratuit, prÃ©cis)
- ğŸ‘¥ **DÃ©tection des speakers** avec Pyannote (identification des intervenants)
- ğŸ¤– **Analyse IA** avec Claude pour suggÃ©rer les meilleurs dÃ©coupages
- ğŸµ **Habillage sonore** avec intro et outro configurables
- âœ‚ï¸ **Montage automatique** avec fondus et silences configurables
- ğŸ“Š **Normalisation audio** pour un volume constant
- ğŸšï¸ **Configuration flexible** via YAML
- ğŸ’¾ **Export** en MP3, WAV, OGG
- ğŸ¨ **Labels Audacity** pour Ã©dition visuelle

---

## ğŸ“‹ PrÃ©requis

- Python 3.8+
- FFmpeg
- (Optionnel) ClÃ© API Anthropic pour le mode automatique
- (Optionnel) Token HuggingFace pour la dÃ©tection des speakers

### Installation de FFmpeg

**Ubuntu/Debian :**
```bash
sudo apt update && sudo apt install ffmpeg
```

**macOS (Homebrew) :**
```bash
brew install ffmpeg
```

**Windows :**
TÃ©lÃ©charger depuis [ffmpeg.org](https://ffmpeg.org/download.html)

---

## ğŸš€ Installation

### 1. Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/lebidul/podcasteur.git
cd podcasteur
```

### 2. CrÃ©er un environnement virtuel

```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 4. Installer Podcasteur

```bash
pip install -e .
```

### 5. Configurer les clÃ©s API

```bash
cp .env.example .env
# Ã‰ditez .env et ajoutez :
# - ANTHROPIC_API_KEY (obligatoire pour mode automatique)
# - HUGGINGFACE_TOKEN (optionnel, pour dÃ©tection speakers)
```

**Obtenir les clÃ©s :**
- Anthropic : https://console.anthropic.com
- HuggingFace : https://huggingface.co/settings/tokens

**Pour la dÃ©tection des speakers, acceptez aussi les conditions sur :**
- https://huggingface.co/pyannote/speaker-diarization-3.1
- https://huggingface.co/pyannote/segmentation-3.0

### 6. (Optionnel) Configurer les Ã©lÃ©ments sonores

```bash
mkdir assets
# Placez vos fichiers intro.mp3 et outro.mp3 dans assets/
# Activez dans config/default_config.yaml : elements_sonores.activer: true
```

---

## ğŸ“– Utilisation

### Mode Automatique (avec IA)

Transcription + analyse IA + montage automatique :

```bash
# Exemple simple - dossier complet
podcasteur auto audio/ --duree 5

# Avec dÃ©tection des speakers
podcasteur auto audio/ --duree 5 --detect-speakers

# Avec fichiers spÃ©cifiques
podcasteur auto enreg_01.wav enreg_02.wav --duree 5 --ton "dynamique"

# Workflow accÃ©lÃ©rÃ© avec fichier mix existant
podcasteur auto --mix sortie/mix_complet.wav --duree 5

# Avec transcription existante (skip Whisper)
podcasteur auto audio/ --transcription transcript.txt --duree 5

# Combo ultra-rapide : skip concat + transcription
podcasteur auto --mix sortie/mix_complet.wav \
                --transcription sortie/transcription.txt \
                --duree 3

# Avec configuration personnalisÃ©e
podcasteur auto *.wav --config ma_config.yaml
```

**Options :**
- `--duree, -d` : DurÃ©e cible en minutes
- `--ton, -t` : Ton souhaitÃ© (ex: "dÃ©tendu et conversationnel")
- `--detect-speakers` : Activer la dÃ©tection des intervenants
- `--mix` : Fichier audio dÃ©jÃ  concatÃ©nÃ© (skip la concatÃ©nation)
- `--transcription` : Fichier de transcription existant (skip la transcription)
- `--sortie, -o` : Dossier de sortie (dÃ©faut: `sortie/`)
- `--config, -c` : Fichier de configuration personnalisÃ©

**Sortie gÃ©nÃ©rÃ©e :**
```
sortie/
â””â”€â”€ podcast_titre_20241005_143052/
    â”œâ”€â”€ podcast_titre_20241005_143052.mp3   # Le podcast final (avec intro/outro si configurÃ©)
    â”œâ”€â”€ podcast_titre_20241005_143052.json  # MÃ©tadonnÃ©es complÃ¨tes
    â””â”€â”€ podcast_titre_20241005_143052.txt   # Labels Audacity
```

**Ã‰dition dans Audacity :**
1. Ouvrir le MP3 dans Audacity
2. `Fichier > Importer > Labels...` â†’ SÃ©lectionner le .txt
3. Tous les segments apparaissent dÃ©limitÃ©s (y compris intro/outro)

### Mode Manuel (dÃ©coupage prÃ©dÃ©fini)

Montage direct depuis un fichier JSON :

```bash
# 1. CrÃ©er un fichier de dÃ©coupage d'exemple
podcasteur exemple mon_decoupage.json

# 2. Ã‰diter le fichier JSON selon vos besoins

# 3. Lancer le montage
podcasteur manuel mon_decoupage.json dossier_audio/ --sortie mon_podcast/
```

**Format du fichier de dÃ©coupage :**

```json
{
  "segments": [
    {
      "fichier": "enregistrement_01.wav",
      "debut": 166.0,
      "fin": 268.0,
      "description": "Introduction"
    },
    {
      "fichier": "enregistrement_02.wav",
      "debut": 45.0,
      "fin": 120.0,
      "description": "Interview principale"
    }
  ],
  "parametres": {
    "duree_fondu": 500,
    "silence_entre_segments": 1000
  }
}
```

### Autres commandes

```bash
# CrÃ©er une configuration personnalisÃ©e
podcasteur init-config --sortie ma_config.yaml

# Afficher les informations
podcasteur info

# Aide
podcasteur --help
podcasteur auto --help
podcasteur manuel --help
```

---

## âš™ï¸ Configuration

### Fichier de configuration (YAML)

CrÃ©ez votre configuration personnalisÃ©e :

```bash
podcasteur init-config --sortie config/ma_config.yaml
```

Ã‰ditez ensuite le fichier pour ajuster :

```yaml
# ParamÃ¨tres audio
audio:
  format_export: "mp3"        # mp3, wav, ogg
  debit: "192k"               # 128k, 192k, 256k, 320k
  duree_fondu: 500            # DurÃ©e des fondus (ms)
  silence_entre_segments: 1000 # Silence entre segments (ms)
  normaliser: true            # Normaliser le volume

# Ã‰lÃ©ments sonores (intro/outro)
elements_sonores:
  activer: false              # Activer/dÃ©sactiver
  generique_debut:
    fichier: "assets/intro.mp3"
    duree_fondu_sortie: 1000
  generique_fin:
    fichier: "assets/outro.mp3"
    duree_fondu_entree: 1000

# Transcription avec WhisperX
transcription:
  modele: "base"              # tiny, base, small, medium, large-v2
  langue: "fr"                # Code langue
  dossier_sortie: "transcriptions"

# Analyse IA
analyse_ia:
  modele: "claude-sonnet-4-5-20250929"
  duree_cible: 5              # DurÃ©e cible en minutes
  ton: "informatif et dynamique"
  nombre_suggestions: 3       # Nombre de propositions
  temperature: 0.7            # CrÃ©ativitÃ© (0.0-1.0)

# Validation
validation:
  verifier_timestamps: true
  tolerance_timestamps: 0.5   # TolÃ©rance en secondes
```

---

## ğŸ¯ Exemples d'utilisation

### Cas d'usage 1 : Podcast avec identification des speakers

```bash
podcasteur auto audio_bidul/ --duree 5 --detect-speakers --ton "dÃ©tendu et convivial"

# L'outil va :
# 1. ConcatÃ©ner tous les fichiers du dossier
# 2. Transcrire avec WhisperX
# 3. DÃ©tecter les speakers (SPEAKER_00, SPEAKER_01, etc.)
# 4. Analyser avec Claude
# 5. Proposer 3 dÃ©coupages
# 6. CrÃ©er le(s) montage(s) final(aux) avec intro/outro si configurÃ©
```

### Cas d'usage 2 : Workflow ultra-rapide (rÃ©-Ã©dition)

```bash
# Utiliser mix et transcription existants pour tester diffÃ©rentes durÃ©es
podcasteur auto --mix sortie/mix_complet.wav \
                --transcription sortie/transcription.txt \
                --duree 3

# â†’ Skip concat + transcription = analyse IA directe
# â†’ Gain de temps considÃ©rable pour itÃ©rations multiples
```

### Cas d'usage 3 : Podcast avec habillage sonore

```bash
# 1. Activer les Ã©lÃ©ments sonores dans la config
# elements_sonores.activer: true

# 2. Lancer le workflow
podcasteur auto audio/ --duree 5

# â†’ Podcast final = [Intro 8s] + [Contenu 5min] + [Outro 12s]
# â†’ MÃ©tadonnÃ©es et labels incluent intro/outro
```

### Cas d'usage 4 : Affinage progressif avec Claude

```bash
podcasteur auto audio/ --duree 5

# 1Ã¨re itÃ©ration : suggestions de base
# Choix : r
# Feedback : "Plus court, 3 minutes max, garde les moments drÃ´les"
# â†’ Nouvelles suggestions

# 2Ã¨me itÃ©ration : suggestions affinÃ©es
# Choix : 2
# â†’ Montage final
```

### Cas d'usage 5 : SÃ©rie de podcasts avec mÃªme configuration

```bash
# CrÃ©er votre config une fois
podcasteur init-config --sortie serie_config.yaml

# Utiliser pour chaque Ã©pisode
podcasteur auto episode1/*.wav --config serie_config.yaml --sortie ep1/
podcasteur auto episode2/*.wav --config serie_config.yaml --sortie ep2/
```

---

## ğŸ“ Structure du projet

```
podcasteur/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py              # Interface ligne de commande
â”‚   â”œâ”€â”€ editor.py           # Orchestration des workflows
â”‚   â”œâ”€â”€ audio_processor.py  # Traitement audio
â”‚   â”œâ”€â”€ transcriber.py      # Transcription WhisperX
â”‚   â”œâ”€â”€ ai_analyzer.py      # Analyse IA avec Claude
â”‚   â””â”€â”€ decoupage.py        # Gestion des dÃ©coupages manuels
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ intro.mp3           # GÃ©nÃ©rique de dÃ©but (optionnel)
â”‚   â””â”€â”€ outro.mp3           # GÃ©nÃ©rique de fin (optionnel)
â”œâ”€â”€ config/
â”‚   â””â”€â”€ default_config.yaml # Configuration par dÃ©faut
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ ...                 # Tests unitaires
â”œâ”€â”€ .env.example            # Exemple de configuration
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ setup.py               # Installation du package
â””â”€â”€ README.md              # Documentation
```

---

## ğŸ”§ Architecture technique

### Workflow Automatique

```
Fichiers audio multiples (ou --mix)
    â†“
[AudioProcessor] ConcatÃ©nation sÃ©quentielle (ou skip si --mix)
    â†“
mix_complet.wav
    â†“
[Transcriber] Transcription WhisperX (ou skip si --transcription)
    â†“
transcription.txt + timestamps + speakers (optionnel)
    â†“
[AIAnalyzer] Analyse avec Claude API
    â†“
Suggestions de dÃ©coupage (JSON)
    â†“
[Interface utilisateur] SÃ©lection
    â†“
[AudioProcessor] Montage final
    â†“
[AudioProcessor] Ajout intro/outro (optionnel)
    â†“
podcast_final.mp3 + mÃ©tadonnÃ©es + labels
```

### Workflow Manuel

```
Fichiers audio multiples + decoupage.json
    â†“
[Decoupage] Validation des timestamps
    â†“
[Decoupage] Chargement des segments
    â†“
[AudioProcessor] Montage avec fondus
    â†“
[AudioProcessor] Ajout intro/outro (optionnel)
    â†“
podcast_final.mp3 + mÃ©tadonnÃ©es + labels
```

---

## ğŸ“ Concepts clÃ©s

### Fondus (Fades)

Les fondus en entrÃ©e et sortie adoucissent les transitions entre segments :
- **Fondu d'entrÃ©e** : le volume monte progressivement
- **Fondu de sortie** : le volume descend progressivement
- DurÃ©e configurable (dÃ©faut : 500ms)

### Normalisation

La normalisation ajuste le volume pour qu'il soit constant dans tout le podcast. RecommandÃ© pour mixer des sources avec des volumes diffÃ©rents.

### Transcription avec WhisperX

WhisperX transcrit l'audio en texte avec timestamps prÃ©cis :
- 70% plus rapide que Whisper classique
- Timestamps prÃ©cis au mot grÃ¢ce Ã  l'alignement forcÃ©
- OptimisÃ© pour le franÃ§ais
- Support de la diarisation intÃ©grÃ©e

### Diarisation (dÃ©tection des speakers)

La diarisation identifie automatiquement les diffÃ©rents intervenants dans un enregistrement :
- Utilise Pyannote.audio pour l'analyse
- Attribution automatique par segment (SPEAKER_00, SPEAKER_01, etc.)
- Visible dans la transcription et les mÃ©tadonnÃ©es
- NÃ©cessite un token HuggingFace

### Analyse IA

Claude analyse la transcription et suggÃ¨re les meilleurs segments selon :
- La durÃ©e cible
- Le ton souhaitÃ©
- La cohÃ©rence narrative
- Les moments intÃ©ressants

### Ã‰lÃ©ments sonores

Intro et outro sont ajoutÃ©s automatiquement au montage final :
- Fondus configurables pour transitions douces
- Timestamps ajustÃ©s dans mÃ©tadonnÃ©es et labels
- Inclus comme segments distincts dans le JSON

---

## ğŸ› DÃ©pannage

### Erreur : FFmpeg not found

```bash
# VÃ©rifier l'installation
ffmpeg -version

# Si absent, installer (voir section PrÃ©requis)
```

### Erreur : ANTHROPIC_API_KEY manquante

```bash
# CrÃ©er le fichier .env
cp .env.example .env

# Ã‰diter et ajouter votre clÃ©
nano .env
```

### Erreur : DÃ©tection des speakers ne fonctionne pas

1. VÃ©rifiez que vous avez acceptÃ© les conditions sur HuggingFace
2. Attendez 5-10 minutes aprÃ¨s l'acceptation
3. VÃ©rifiez votre token dans `.env`
4. Essayez de rÃ©gÃ©nÃ©rer un nouveau token

### Erreur : ModÃ¨le WhisperX trÃ¨s lent

Le modÃ¨le `base` est rapide. Si vous avez utilisÃ© `medium` ou `large`, essayez :

```yaml
transcription:
  modele: "base"  # Plus rapide
```

Avec GPU, les performances sont 10-20x meilleures.

### Timestamps invalides dans le dÃ©coupage manuel

L'outil valide automatiquement et vous avertit. Ajustez dans le fichier JSON :

```json
{
  "segments": [
    {
      "fichier": "audio.wav",
      "debut": 10.0,
      "fin": 50.0  // Assurez-vous que fin < durÃ©e du fichier
    }
  ]
}
```

### QualitÃ© audio mÃ©diocre

Augmentez le bitrate dans la config :

```yaml
audio:
  debit: "320k"  # Meilleure qualitÃ©
```

### Intro/Outro non trouvÃ©s

VÃ©rifiez les chemins dans la config :

```yaml
elements_sonores:
  generique_debut:
    fichier: "assets/intro.mp3"  # Chemin relatif Ã  la racine
```

---

## ğŸš€ DÃ©veloppement

### Installation en mode dÃ©veloppement

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/lebidul/podcasteur.git
cd podcasteur

# Environnement virtuel
python3 -m venv venv
source venv/bin/activate

# Installation en mode Ã©ditable
pip install -e .

# Installer les dÃ©pendances de dÃ©veloppement
pip install pytest pytest-cov black flake8
```

### Tests

```bash
# Lancer les tests
pytest

# Avec couverture
pytest --cov=src tests/

# Tests spÃ©cifiques
pytest tests/test_audio_processor.py
```

### Formatage du code

```bash
# Formater avec Black
black src/

# VÃ©rifier avec Flake8
flake8 src/
```

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. **Fork** le projet
2. CrÃ©ez une **branche** pour votre fonctionnalitÃ© (`git checkout -b feature/nouvelle-fonctionnalite`)
3. **Committez** vos changements (`git commit -m 'Ajout nouvelle fonctionnalitÃ©'`)
4. **Pushez** vers la branche (`git push origin feature/nouvelle-fonctionnalite`)
5. Ouvrez une **Pull Request**

### Guidelines

- Code en franÃ§ais (commentaires, variables, messages)
- Suivre la convention PEP 8
- Ajouter des tests pour les nouvelles fonctionnalitÃ©s
- Mettre Ã  jour la documentation

---

## ğŸ“ TODO / Roadmap

- [x] DÃ©tection automatique des speakers (v1.4.0)
- [x] Ajout automatique d'intro/outro (v1.4.0)
- [ ] Interface graphique (GUI) avec PyQt ou Tkinter
- [ ] Virgules sonores entre segments
- [ ] DÃ©tection automatique des silences Ã  couper
- [ ] Ã‰galisation audio avancÃ©e
- [ ] Export vers plateformes de podcast
- [ ] Support multi-langues pour l'interface
- [ ] Mode batch pour traiter plusieurs podcasts
- [ ] IntÃ©gration avec services de stockage cloud
- [ ] API REST pour intÃ©gration externe

---

## ğŸ“„ Licence

MIT License

Copyright (c) 2024 Projet Bidul

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

---

## ğŸ™ Remerciements

- **WhisperX** (Max Bain) pour la transcription amÃ©liorÃ©e
- **Pyannote** (HervÃ© Bredin) pour la diarisation
- **Claude** (Anthropic) pour l'analyse IA
- **PyDub** pour le traitement audio
- **Click** pour l'interface CLI
- Le collectif du **Bidul** et le **Blue Zinc** au Mans pour l'inspiration

---

## ğŸ“ Contact

- **Projet** : https://github.com/lebidul/podcasteur
- **Issues** : https://github.com/lebidul/podcasteur/issues
- **Le Bidul** : [Fanzine culturel du Mans](https://lebidul.org)

---

## ğŸ“Š Statistiques

![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Version](https://img.shields.io/badge/version-1.4.0-blue.svg)
![Status](https://img.shields.io/badge/status-beta-orange.svg)

---

**Fait avec â¤ï¸ pour la communautÃ© du Bidul**