"""
Module d'analyse IA utilisant l'API Claude
"""

import anthropic
import json
from typing import List, Dict, Optional
from pathlib import Path


class AIAnalyzer:
    """Analyse les transcriptions et suggÃ¨re des points de montage avec Claude"""
    
    def __init__(self, config: dict, cle_api: str):
        """
        Initialise l'analyseur IA
        
        Args:
            config: Dictionnaire de configuration
            cle_api: ClÃ© API Anthropic
        """
        self.config = config['analyse_ia']
        self.client = anthropic.Anthropic(api_key=cle_api)
    
    def analyser_transcription(
        self, 
        transcription: dict,
        duree_cible: Optional[int] = None,
        ton: Optional[str] = None,
        nombre_suggestions: Optional[int] = None
    ) -> List[Dict]:
        """
        Analyse la transcription et suggÃ¨re des segments de montage
        
        Args:
            transcription: Dictionnaire de transcription avec 'texte' et 'segments'
            duree_cible: DurÃ©e cible en minutes (remplace la config)
            ton: Ton souhaitÃ© (remplace la config)
            nombre_suggestions: Nombre de suggestions (remplace la config)
            
        Returns:
            Liste de dictionnaires de suggestions
        """
        # Utiliser les valeurs fournies ou celles de la config
        duree_cible = duree_cible or self.config['duree_cible']
        ton = ton or self.config['ton']
        nombre_suggestions = nombre_suggestions or self.config['nombre_suggestions']
        
        print(f"ğŸ¤– Analyse de la transcription avec Claude...")
        print(f"   DurÃ©e cible : {duree_cible} minutes")
        print(f"   Ton souhaitÃ© : {ton}")
        print(f"   Suggestions Ã  gÃ©nÃ©rer : {nombre_suggestions}")
        
        # Construire le prompt
        prompt = self._construire_prompt(
            transcription, 
            duree_cible, 
            ton, 
            nombre_suggestions
        )
        
        # Appeler l'API Claude
        reponse = self.client.messages.create(
            model=self.config['modele'],
            max_tokens=4096,
            temperature=self.config['temperature'],
            messages=[{
                "role": "user",
                "content": prompt
            }]
        )
        
        # Parser la rÃ©ponse
        suggestions = self._parser_reponse(reponse.content[0].text)
        
        print(f"âœ… Analyse terminÃ©e : {len(suggestions)} suggestions gÃ©nÃ©rÃ©es")
        
        return suggestions
    
    def _construire_prompt(
        self, 
        transcription: dict, 
        duree_cible: int, 
        ton: str, 
        nombre_suggestions: int
    ) -> str:
        """Construit le prompt pour Claude"""
        
        # Formater la transcription avec timestamps
        transcription_formatee = self._formater_transcription_pour_prompt(transcription)
        
        prompt = f"""Tu es un expert en montage de podcasts. Analyse cette transcription d'un reportage audio et propose {nombre_suggestions} dÃ©coupages diffÃ©rents.

TRANSCRIPTION AVEC TIMESTAMPS:
{transcription_formatee}

CONSIGNES:
- DurÃ©e cible du podcast final: {duree_cible} minutes
- Ton souhaitÃ©: {ton}
- Identifie les moments les plus intÃ©ressants, dynamiques, et pertinents
- Pour chaque suggestion, fournis:
  1. Un titre descriptif
  2. Une liste de segments Ã  garder (avec timestamps debut/fin en secondes)
  3. Un commentaire expliquant les choix de montage
  4. La durÃ©e totale estimÃ©e

IMPORTANT: Ta rÃ©ponse doit Ãªtre au format JSON suivant (et UNIQUEMENT du JSON valide, sans texte avant ou aprÃ¨s):

{{
  "suggestions": [
    {{
      "titre": "Titre de la suggestion",
      "commentaire": "Explication des choix de montage",
      "duree_estimee": duree_en_minutes,
      "segments": [
        {{"debut": temps_debut_en_secondes, "fin": temps_fin_en_secondes, "description": "Description du segment"}},
        ...
      ]
    }},
    ...
  ]
}}

GÃ©nÃ¨re maintenant les {nombre_suggestions} suggestions."""

        return prompt
    
    def _formater_transcription_pour_prompt(self, transcription: dict) -> str:
        """Formate la transcription avec timestamps pour le prompt"""
        lignes = []
        for seg in transcription['segments']:
            debut = self._formater_temps(seg['debut'])
            fin = self._formater_temps(seg['fin'])
            lignes.append(f"[{debut} - {fin}] {seg['texte']}")
        return "\n".join(lignes)
    
    def _parser_reponse(self, texte_reponse: str) -> List[Dict]:
        """Parse la rÃ©ponse JSON de Claude"""
        try:
            # Essayer d'extraire le JSON de la rÃ©ponse (au cas oÃ¹ il y aurait du texte en plus)
            idx_debut = texte_reponse.find('{')
            idx_fin = texte_reponse.rfind('}') + 1
            
            if idx_debut == -1 or idx_fin == 0:
                raise ValueError("Aucun JSON trouvÃ© dans la rÃ©ponse")
            
            texte_json = texte_reponse[idx_debut:idx_fin]
            donnees = json.loads(texte_json)
            
            return donnees.get('suggestions', [])
            
        except json.JSONDecodeError as e:
            print(f"âŒ Erreur lors du parsing de la rÃ©ponse Claude : {e}")
            print(f"Texte de la rÃ©ponse : {texte_reponse[:500]}...")
            raise
    
    @staticmethod
    def _formater_temps(secondes: float) -> str:
        """Formate les secondes en MM:SS"""
        minutes = int(secondes // 60)
        secs = int(secondes % 60)
        return f"{minutes:02d}:{secs:02d}"
    
    def sauvegarder_suggestions(self, suggestions: List[Dict], chemin_sortie: Path):
        """Sauvegarde les suggestions dans un fichier JSON"""
        chemin_sortie.parent.mkdir(parents=True, exist_ok=True)
        
        with open(chemin_sortie, 'w', encoding='utf-8') as f:
            json.dump({"suggestions": suggestions}, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ Suggestions sauvegardÃ©es dans {chemin_sortie}")
